% Generated by IEEEtran.bst, version: 1.12 (2007/01/11)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Mnih2013PlayingAW}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra, and
  M.~A. Riedmiller, ``Playing atari with deep reinforcement learning,''
  \emph{ArXiv}, vol. abs/1312.5602, 2013.

\bibitem{Silver2017MasteringTG}
D.~Silver, J.~Schrittwieser, K.~Simonyan, I.~Antonoglou, A.~Huang, A.~Guez,
  T.~Hubert, L.~Baker, M.~Lai, A.~Bolton, Y.~Chen, T.~Lillicrap, F.~Hui,
  L.~Sifre, G.~van~den Driessche, T.~Graepel, and D.~Hassabis, ``Mastering the
  game of go without human knowledge,'' \emph{Nature}, vol. 550, pp. 354--359,
  2017.

\bibitem{Lillicrap2016ContinuousCW}
T.~Lillicrap, J.~Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa, D.~Silver, and
  D.~Wierstra, ``Continuous control with deep reinforcement learning,''
  \emph{CoRR}, vol. abs/1509.02971, 2016.

\bibitem{ShalevShwartz2016SafeMR}
S.~Shalev-Shwartz, S.~Shammah, and A.~Shashua, ``Safe, multi-agent,
  reinforcement learning for autonomous driving,'' \emph{ArXiv}, vol.
  abs/1610.03295, 2016.

\bibitem{Sutton2005ReinforcementLA}
R.~Sutton and A.~Barto, ``Reinforcement learning: An introduction,'' \emph{IEEE
  Transactions on Neural Networks}, vol.~16, pp. 285--286, 2005.

\bibitem{Szepesvari2010AlgorithmsFR}
C.~Szepesvari, ``Algorithms for reinforcement learning,'' in \emph{Algorithms
  for Reinforcement Learning}, 2010.

\bibitem{Wang2020OnRR}
R.~Wang, S.~Du, L.~F. Yang, and R.~Salakhutdinov, ``On reward-free
  reinforcement learning with linear function approximation,'' \emph{ArXiv},
  vol. abs/2006.11274, 2020.

\bibitem{Bradtke2004LinearLA}
S.~J. Bradtke and A.~Barto, ``Linear least-squares algorithms for temporal
  difference learning,'' \emph{Machine Learning}, vol.~22, pp. 33--57, 2004.

\bibitem{Sutton2005LearningTP}
R.~Sutton, ``Learning to predict by the methods of temporal differences,''
  \emph{Machine Learning}, vol.~3, pp. 9--44, 2005.

\bibitem{Geramifard2006IncrementalLT}
A.~Geramifard, M.~Bowling, and R.~Sutton, ``Incremental least-squares temporal
  difference learning,'' in \emph{AAAI}, 2006.

\bibitem{Kolter2009RegularizationAF}
J.~Z. Kolter and A.~Ng, ``Regularization and feature selection in least-squares
  temporal difference learning,'' in \emph{ICML '09}, 2009.

\bibitem{Johns2010LinearCF}
J.~Johns, C.~Painter-Wakefield, and R.~Parr, ``Linear complementarity for
  regularized policy evaluation and improvement,'' in \emph{NIPS}, 2010.

\bibitem{Petrik2010FeatureSU}
M.~Petrik, G.~Taylor, R.~Parr, and S.~Zilberstein, ``Feature selection using
  regularization in approximate linear programs for markov decision
  processes,'' in \emph{ICML}, 2010.

\bibitem{Parr2008AnAO}
R.~Parr, L.~Li, G.~Taylor, C.~Painter-Wakefield, and M.~Littman, ``An analysis
  of linear models, linear value-function approximation, and feature selection
  for reinforcement learning,'' in \emph{ICML '08}, 2008.

\bibitem{Petrik2007AnAO}
M.~Petrik, ``An analysis of laplacian methods for value function approximation
  in mdps,'' in \emph{IJCAI}, 2007.

\bibitem{Parr2007AnalyzingFG}
R.~Parr, C.~Painter-Wakefield, L.~Li, and M.~Littman, ``Analyzing feature
  generation for value-function approximation,'' in \emph{ICML '07}, 2007.

\bibitem{Song2016LinearFE}
Z.~Song, R.~Parr, X.~Liao, and L.~Carin, ``Linear feature encoding for
  reinforcement learning,'' in \emph{NIPS}, 2016.

\bibitem{Behzadian2019FeatureSB}
B.~Behzadian, ``Feature selection by singular value decomposition for
  reinforcement learning,'' 2019.

\bibitem{Puterman1994MarkovDP}
M.~Puterman, ``Markov decision processes: Discrete stochastic dynamic
  programming,'' in \emph{Wiley Series in Probability and Statistics}, 1994.

\bibitem{Koller1999ComputingFV}
D.~Koller and R.~Parr, ``Computing factored value functions for policies in
  structured mdps,'' in \emph{IJCAI}, 1999.

\bibitem{EtAl2007MatrixC3}
G.~G.~H. Et.Al, ``Matrix computations, 4th edition,'' 2016.

\bibitem{Williams1993TightPB}
R.~J. Williams and L.~Baird, ``Tight performance bounds on greedy policies
  based on imperfect value functions,'' 1993.

\bibitem{Lagoudakis2003LeastSquaresPI}
M.~Lagoudakis and R.~Parr, ``Least-squares policy iteration,'' \emph{J. Mach.
  Learn. Res.}, vol.~4, pp. 1107--1149, 2003.

\end{thebibliography}
